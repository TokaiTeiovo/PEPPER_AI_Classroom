2025-05-13 13:26:35,085 - INFO - ÕıÔÚ¼ÓÔØÄ£ĞÍ: models/deepseek-coder-1.3b-base
2025-05-13 13:26:35,163 - INFO - ÒÑÆôÓÃcudnn benchmark
2025-05-13 13:26:35,163 - INFO - ÕıÔÚÔ¤ÈÈGPU...
2025-05-13 13:26:35,598 - INFO - GPUÔ¤ÈÈÍê³É
2025-05-13 13:26:35,600 - INFO - GPU: NVIDIA GeForce GTX 1650
2025-05-13 13:26:35,601 - INFO - GPUÄÚ´æ: ×Ü¼Æ=4.29GB
2025-05-13 13:26:35,602 - INFO - CUDA°æ±¾: 12.8
2025-05-13 13:26:35,602 - INFO - ÕıÔÚ¼ÓÔØ·Ö´ÊÆ÷...
2025-05-13 13:26:35,744 - INFO - ·Ö´ÊÆ÷¼ÓÔØÍê³É
2025-05-13 13:26:35,744 - INFO - ÕıÔÚ¼ÓÔØÄ£ĞÍ...
2025-05-13 13:26:35,788 - INFO - Ê¹ÓÃ8Î»Á¿»¯¼ÓÔØÄ£ĞÍÒÔ½ÚÊ¡GPUÄÚ´æ
2025-05-13 13:26:39,550 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-05-13 13:26:44,263 - INFO - Ä£ĞÍ¼ÓÔØÍê³É
2025-05-13 13:26:44,264 - INFO - GPUÄÚ´æÊ¹ÓÃ: 1.49GB
2025-05-13 13:26:44,284 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.4.179.65:5000
2025-05-13 13:26:44,285 - INFO - [33mPress CTRL+C to quit[0m
2025-05-13 13:26:57,869 - INFO - 127.0.0.1 - - [13/May/2025 13:26:57] "GET /health HTTP/1.1" 200 -
2025-05-13 13:27:16,400 - INFO - ÊÕµ½²éÑ¯: Äã...
2025-05-13 13:27:16,438 - INFO - ¿ªÊ¼Éú³É»Ø´ğ...
2025-05-13 13:27:59,133 - INFO - Éú³ÉÍê³É: 338×Ö·û, ºÄÊ±=42.69Ãë
2025-05-13 13:27:59,137 - INFO - 127.0.0.1 - - [13/May/2025 13:27:59] "POST /llm/query HTTP/1.1" 200 -
2025-05-13 13:32:14,024 - INFO - ÊÕµ½²éÑ¯: ÄãºÃ...
2025-05-13 13:32:14,026 - INFO - ¿ªÊ¼Éú³É»Ø´ğ...
2025-05-13 13:32:25,927 - INFO - Éú³ÉÍê³É: 85×Ö·û, ºÄÊ±=11.87Ãë
2025-05-13 13:32:25,929 - INFO - 127.0.0.1 - - [13/May/2025 13:32:25] "POST /llm/query HTTP/1.1" 200 -
