#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
PEPPERæ™ºèƒ½æ•™å­¦ç³»ç»Ÿ - å¢å¼ºAPIæœåŠ¡å™¨
æ”¯æŒå¤§è¯­è¨€æ¨¡å‹ã€çŸ¥è¯†å›¾è°±ã€å¤šæ¨¡æ€äº¤äº’ã€æ™ºèƒ½æ•™å­¦å››å¤§åŠŸèƒ½æ¨¡å—
"""
import json
import logging
import os
import sys
import uuid
from datetime import datetime

from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from werkzeug.utils import secure_filename

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

# å¯¼å…¥å„ä¸ªæ¨¡å—
from ai_service.llm_module.llm_interface import LLMService
from ai_service.llm_module.lora_fine_tuning import LoRAFineTuner
from ai_service.knowledge_graph.knowledge_graph import KnowledgeGraph
from ai_service.knowledge_graph.education_knowledge_processor import EducationKnowledgeProcessor
from ai_service.multimodal.speech_recognition import SpeechRecognizer
from ai_service.multimodal.image_recognition import ImageRecognizer
from ai_service.multimodal.text_processor import TextProcessor
from ai_service.teaching_module.personalized_teaching import PersonalizedTeaching

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("PEPPER_API")

app = Flask(__name__)
CORS(app)

# å…¨å±€å˜é‡å­˜å‚¨æœåŠ¡å®ä¾‹
services = {
    'llm': None,
    'fine_tuner': None,
    'knowledge_graph': None,
    'knowledge_processor': None,
    'speech_recognizer': None,
    'image_recognizer': None,
    'text_processor': None,
    'teaching': None
}

# ç³»ç»ŸçŠ¶æ€
system_status = {
    'model_loaded': False,
    'neo4j_connected': False,
    'training_progress': 0,
    'training_active': False
}

# é…ç½®
UPLOAD_FOLDER = 'uploads'
REPORTS_FOLDER = 'reports'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(REPORTS_FOLDER, exist_ok=True)

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size


def initialize_services():
    """åˆå§‹åŒ–æœåŠ¡"""
    try:
        # åˆå§‹åŒ–æ–‡æœ¬å¤„ç†å™¨
        services['text_processor'] = TextProcessor()

        # åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨
        services['speech_recognizer'] = SpeechRecognizer()

        # åˆå§‹åŒ–å›¾åƒè¯†åˆ«å™¨
        services['image_recognizer'] = ImageRecognizer()

        logger.info("åŸºç¡€æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        logger.error(f"æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")


# ======================== å¤§è¯­è¨€æ¨¡å‹API ========================

@app.route('/api/load_model', methods=['POST'])
def load_model():
    """åŠ è½½å¤§è¯­è¨€æ¨¡å‹"""
    try:
        data = request.json
        # ä¿®å¤ï¼šç¡®ä¿dataä¸ä¸ºç©º
        if not data:
            return jsonify({
                "status": "error",
                "message": "è¯·æ±‚æ•°æ®ä¸ºç©º"
            })
        model_path = data.get('model_path', '')
        use_4bit = data.get('use_4bit', True)  # é»˜è®¤ä½¿ç”¨4bité‡åŒ–
        use_8bit = data.get('use_8bit', False)
        use_lora = data.get("use_lora", False)
        lora_path = data.get("lora_path", None)
        logger.info(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")

        # ä¿®å¤ï¼šæ£€æŸ¥model_pathæ˜¯å¦ä¸ºç©º
        if not model_path or model_path.strip() == '':
            return jsonify({
                "status": "error",
                "message": "æ¨¡å‹è·¯å¾„ä¸èƒ½ä¸ºç©º"
            })

        logger.info(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")

        if use_4bit:
            logger.info("ä½¿ç”¨4bité‡åŒ–åŠ è½½æ¨¡å‹")
        elif use_8bit:
            logger.info("ä½¿ç”¨8bité‡åŒ–åŠ è½½æ¨¡å‹")
        else:
            logger.info("ä½¿ç”¨å…¨ç²¾åº¦åŠ è½½æ¨¡å‹")

        if not os.path.exists(model_path):
            return jsonify({
                "status": "error",
                "message": f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}"
            })

        # ä¿®å¤ï¼šåˆ›å»ºLLMServiceè€Œä¸æ˜¯LoRAFineTunerï¼ˆç”¨äºæ¨ç†ï¼‰
        try:
            # å¦‚æœæ˜¯å¾®è°ƒåçš„æ¨¡å‹ï¼Œä½¿ç”¨LoRAFineTuner
            if 'deepseek-' in model_path and any(
                    x in model_path for x in ['_4bit', '_8bit', '20241', '20242', '20243']):
                logger.info("æ£€æµ‹åˆ°å¾®è°ƒæ¨¡å‹ï¼Œä½¿ç”¨LoRAåŠ è½½")
                temp_fine_tuner = LoRAFineTuner(model_path)
                success = temp_fine_tuner.load_base_model(use_4bit=use_4bit, use_8bit=use_8bit)
                if success:
                    services['llm'] = temp_fine_tuner
            else:
                # åŸå§‹æ¨¡å‹ï¼Œä½¿ç”¨LLMService
                logger.info("æ£€æµ‹åˆ°åŸå§‹æ¨¡å‹ï¼Œä½¿ç”¨æ ‡å‡†åŠ è½½")
                services['llm'] = LLMService(model_path)
                success = True

        except Exception as e:
            logger.error(f"æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            return jsonify({
                "status": "error",
                "message": f"æ¨¡å‹åˆ›å»ºå¤±è´¥: {str(e)}"
            })

        if success:
            system_status['model_loaded'] = True
            system_status['model_path'] = model_path
            system_status['model_quantization'] = '4bit' if use_4bit else '8bit' if use_8bit else 'full'

            logger.info("æ¨¡å‹åŠ è½½æˆåŠŸ")
            return jsonify({
                "status": "success",
                "message": "æ¨¡å‹åŠ è½½æˆåŠŸ",
                "model_path": model_path,
                "quantization": system_status['model_quantization']
            })
        else:
            return jsonify({
                "status": "error",
                "message": "æ¨¡å‹åŠ è½½å¤±è´¥"
            })

    except Exception as e:
        logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    return jsonify({
        "status": "error",
        "message": f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
    })


@app.route('/api/unload_model', methods=['POST'])
def unload_model():
    """å¸è½½å¤§è¯­è¨€æ¨¡å‹"""
    try:
        services['llm'] = None
        system_status['model_loaded'] = False

        logger.info("æ¨¡å‹å·²å¸è½½")
        return jsonify({
            "status": "success",
            "message": "æ¨¡å‹å·²å¸è½½"
        })

    except Exception as e:
        logger.error(f"æ¨¡å‹å¸è½½å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/test_model', methods=['POST'])
def test_model():
    """æµ‹è¯•å¤§è¯­è¨€æ¨¡å‹"""
    try:
        if not services['llm']:
            return jsonify({
                "status": "error",
                "message": "æ¨¡å‹æœªåŠ è½½"
            })

        data = request.json
        question = data.get('question', '')
        max_tokens = data.get('max_tokens', 512)

        if not question.strip():
            return jsonify({
                "status": "error",
                "message": "é—®é¢˜ä¸èƒ½ä¸ºç©º"
            })

        # ä½¿ç”¨LoRAFineTunerçš„generate_responseæ–¹æ³•
        if hasattr(services['llm'], 'generate_response'):
            response = services['llm'].generate_response(question, max_tokens)
        else:
            # fallbackåˆ°åŸæ¥çš„æ–¹æ³•
            response = services['llm'].generate_response(question, max_tokens)

        return jsonify({
            "status": "success",
            "response": response,
            "model_quantization": system_status.get('model_quantization', 'unknown')
        })

    except Exception as e:
        logger.error(f"æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })

# æ–°å¢ï¼šæ£€æŸ¥é‡åŒ–åº“å®‰è£…çŠ¶æ€
@app.route('/api/check_quantization_support', methods=['GET'])
def check_quantization_support():
    """æ£€æŸ¥é‡åŒ–è®­ç»ƒæ”¯æŒæƒ…å†µ"""
    try:
        support_info = {
            "bitsandbytes_available": False,
            "accelerate_available": False,
            "peft_available": False,
            "torch_version": "",
            "cuda_version": "",
            "recommendations": []
        }

        # æ£€æŸ¥å¿…è¦çš„åº“
        try:
            import bitsandbytes
            support_info["bitsandbytes_available"] = True
            support_info["bitsandbytes_version"] = bitsandbytes.__version__
        except ImportError:
            support_info["recommendations"].append("éœ€è¦å®‰è£…bitsandbytes: pip install bitsandbytes")

        try:
            import accelerate
            support_info["accelerate_available"] = True
            support_info["accelerate_version"] = accelerate.__version__
        except ImportError:
            support_info["recommendations"].append("éœ€è¦å®‰è£…accelerate: pip install accelerate")

        try:
            import peft
            support_info["peft_available"] = True
            support_info["peft_version"] = peft.__version__
        except ImportError:
            support_info["recommendations"].append("éœ€è¦å®‰è£…peft: pip install peft")

        # æ£€æŸ¥PyTorchç‰ˆæœ¬
        try:
            import torch
            support_info["torch_version"] = torch.__version__
            support_info["cuda_version"] = torch.version.cuda if torch.cuda.is_available() else "Not available"
        except ImportError:
            support_info["recommendations"].append("éœ€è¦å®‰è£…PyTorch")

        # åˆ¤æ–­æ˜¯å¦æ”¯æŒé‡åŒ–è®­ç»ƒ
        quantization_ready = (
                support_info["bitsandbytes_available"] and
                support_info["accelerate_available"] and
                support_info["peft_available"]
        )

        support_info["quantization_ready"] = quantization_ready

        if not quantization_ready:
            support_info["recommendations"].append("å®‰è£…å‘½ä»¤: pip install bitsandbytes accelerate peft")

        return jsonify({
            "status": "success",
            "support_info": support_info
        })

    except Exception as e:
        logger.error(f"æ£€æŸ¥é‡åŒ–æ”¯æŒå¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })

@app.route('/api/start_finetuning', methods=['POST'])
def start_finetuning():
    """å¼€å§‹LoRAå¾®è°ƒ"""
    try:
        if 'training_data' not in request.files:
            return jsonify({
                "status": "error",
                "message": "æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶"
            })

        file = request.files['training_data']
        model_path = request.form.get('model_path', '')
        epochs = int(request.form.get('epochs', 3))
        learning_rate = float(request.form.get('learning_rate', 0.0002))
        batch_size = int(request.form.get('batch_size', 2))  # 4bitè®­ç»ƒé»˜è®¤batch_size=2
        use_4bit = request.form.get('use_4bit', 'true').lower() == 'true'
        use_8bit = request.form.get('use_8bit', 'false').lower() == 'true'

        if file.filename == '':
            return jsonify({
                "status": "error",
                "message": "æœªé€‰æ‹©æ–‡ä»¶"
            })

        if not model_path or model_path.strip() == '':
            return jsonify({
                "status": "error",
                "message": "æœªæŒ‡å®šæ¨¡å‹è·¯å¾„"
            })

        # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            return jsonify({
                "status": "error",
                "message": f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}"
            })

        # ä¿å­˜æ–‡ä»¶
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)

        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        quantization_suffix = "_4bit" if use_4bit else "_8bit" if use_8bit else ""
        output_dir = f"models/deepseek-{timestamp}{quantization_suffix}"

        # åˆ›å»ºå¾®è°ƒå™¨ï¼Œä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹è·¯å¾„
        services['fine_tuner'] = LoRAFineTuner(
            base_model_path=model_path,  # ä½¿ç”¨å‰ç«¯ä¼ é€’çš„æ¨¡å‹è·¯å¾„
            output_dir=output_dir
        )

        # è®°å½•è®­ç»ƒä¿¡æ¯åˆ°ç³»ç»ŸçŠ¶æ€
        system_status['training_output_dir'] = output_dir
        system_status['training_start_time'] = datetime.now().isoformat()
        system_status['training_active'] = True
        system_status['training_progress'] = 0
        system_status['training_config'] = {
            'model_path': model_path,
            'epochs': epochs,
            'batch_size': batch_size,
            'learning_rate': learning_rate,
            'use_4bit': use_4bit,
            'use_8bit': use_8bit,
            'quantization': '4bit' if use_4bit else '8bit' if use_8bit else 'none'
        }

        # å¯åŠ¨å¼‚æ­¥è®­ç»ƒä»»åŠ¡
        import threading
        def run_training():
            try:
                logger.info(f"å¼€å§‹4bité‡åŒ–è®­ç»ƒï¼Œæ¨¡å‹å°†ä¿å­˜åˆ°: {output_dir}")

                # åŠ è½½åŸºç¡€æ¨¡å‹
                success = services['fine_tuner'].load_base_model(use_4bit=use_4bit, use_8bit=use_8bit)
                if not success:
                    system_status['training_active'] = False
                    system_status['training_error'] = "æ¨¡å‹åŠ è½½å¤±è´¥"
                    logger.error("æ¨¡å‹åŠ è½½å¤±è´¥")
                    return

                logger.info("æ¨¡å‹åŠ è½½æˆåŠŸï¼Œå‡†å¤‡LoRAé…ç½®")
                # å‡†å¤‡LoRAé…ç½®
                services['fine_tuner'].prepare_lora_config()

                logger.info("å‡†å¤‡æ•°æ®é›†")
                # å‡†å¤‡æ•°æ®é›†
                dataset = services['fine_tuner'].prepare_dataset(data_path=filepath)
                if dataset is None:
                    system_status['training_active'] = False
                    system_status['training_error'] = "æ•°æ®é›†å‡†å¤‡å¤±è´¥"
                    logger.error("æ•°æ®é›†å‡†å¤‡å¤±è´¥")
                    return

                # å¼€å§‹è®­ç»ƒ
                system_status['training_progress'] = 10
                success = services['fine_tuner'].train(
                    dataset,
                    epochs=epochs,
                    batch_size=batch_size,
                    learning_rate=learning_rate
                )

                if success:
                    system_status['training_progress'] = 100
                    system_status['training_end_time'] = datetime.now().isoformat()
                    logger.info(f"4bité‡åŒ–è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜åˆ°: {output_dir}")
                else:
                    system_status['training_error'] = "è®­ç»ƒè¿‡ç¨‹å¤±è´¥"
                    logger.error("è®­ç»ƒè¿‡ç¨‹å¤±è´¥")

            except Exception as e:
                logger.error(f"è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
                system_status['training_error'] = str(e)
            finally:
                system_status['training_active'] = False
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.remove(filepath)
                except:
                    pass

        # å¯åŠ¨è®­ç»ƒçº¿ç¨‹
        thread = threading.Thread(target=run_training)
        thread.daemon = True
        thread.start()

        logger.info(f"4bité‡åŒ–LoRAå¾®è°ƒå·²å¼€å§‹ï¼Œè¾“å‡ºç›®å½•: {output_dir}")
        return jsonify({
            "status": "success",
            "message": "4bité‡åŒ–å¾®è°ƒå·²å¼€å§‹",
            "output_dir": output_dir,
            "timestamp": timestamp,
            "config": system_status['training_config']
        })

    except Exception as e:
        logger.error(f"å¾®è°ƒå¯åŠ¨å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/training_progress', methods=['GET'])
def get_training_progress():
    """è·å–è®­ç»ƒè¿›åº¦ï¼ŒåŒ…å«æ›´è¯¦ç»†çš„ä¿¡æ¯"""
    progress_info = {
        "status": "success",
        "progress": system_status['training_progress'],
        "active": system_status['training_active'],
        "output_dir": system_status.get('training_output_dir', ''),
        "start_time": system_status.get('training_start_time', ''),
        "config": system_status.get('training_config', {}),
    }

    # æ·»åŠ ç»“æŸæ—¶é—´ï¼ˆå¦‚æœæœ‰ï¼‰
    if 'training_end_time' in system_status:
        progress_info["end_time"] = system_status['training_end_time']

    # æ·»åŠ é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if 'training_error' in system_status:
        progress_info["error"] = system_status['training_error']

    # è®¡ç®—é¢„ä¼°å‰©ä½™æ—¶é—´
    if system_status['training_active'] and 'training_start_time' in system_status:
        try:
            start_time = datetime.fromisoformat(system_status['training_start_time'])
            elapsed_time = (datetime.now() - start_time).total_seconds()
            progress = system_status['training_progress']

            if progress > 0:
                estimated_total_time = elapsed_time * 100 / progress
                remaining_time = estimated_total_time - elapsed_time
                progress_info["estimated_remaining_seconds"] = max(0, int(remaining_time))
        except:
            pass

    return jsonify(progress_info)


@app.route('/api/get_quantization_info', methods=['GET'])
def get_quantization_info():
    """è·å–é‡åŒ–è®­ç»ƒä¿¡æ¯å’Œå»ºè®®"""
    try:
        import torch

        # æ£€æŸ¥CUDAå’ŒGPUä¿¡æ¯
        cuda_available = torch.cuda.is_available()
        gpu_info = {}

        if cuda_available:
            gpu_info = {
                "gpu_count": torch.cuda.device_count(),
                "gpu_name": torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else "Unknown",
                "gpu_memory_gb": round(torch.cuda.get_device_properties(0).total_memory / 1024 ** 3, 2) if torch.cuda.device_count() > 0 else 0
            }

        # æ ¹æ®GPUå†…å­˜ç»™å‡ºå»ºè®®
        recommendations = {
            "use_4bit": True,  # é»˜è®¤æ¨è4bit
            "use_8bit": False,
            "recommended_batch_size": 2,
            "reason": "é»˜è®¤æ¨è4bité‡åŒ–ä»¥è·å¾—æœ€ä½³å†…å­˜æ•ˆç‡"
        }

        if cuda_available and gpu_info.get("gpu_memory_gb", 0) > 0:
            gpu_memory = gpu_info["gpu_memory_gb"]

            if gpu_memory >= 24:
                recommendations = {
                    "use_4bit": False,
                    "use_8bit": False,
                    "recommended_batch_size": 8,
                    "reason": f"GPUå†…å­˜å……è¶³({gpu_memory}GB)ï¼Œå¯ä½¿ç”¨å…¨ç²¾åº¦è®­ç»ƒ"
                }
            elif gpu_memory >= 16:
                recommendations = {
                    "use_4bit": False,
                    "use_8bit": True,
                    "recommended_batch_size": 4,
                    "reason": f"GPUå†…å­˜è¾ƒå……è¶³({gpu_memory}GB)ï¼Œæ¨è8bité‡åŒ–"
                }
            elif gpu_memory >= 8:
                recommendations = {
                    "use_4bit": True,
                    "use_8bit": False,
                    "recommended_batch_size": 2,
                    "reason": f"GPUå†…å­˜ä¸­ç­‰({gpu_memory}GB)ï¼Œæ¨è4bité‡åŒ–"
                }
            else:
                recommendations = {
                    "use_4bit": True,
                    "use_8bit": False,
                    "recommended_batch_size": 1,
                    "reason": f"GPUå†…å­˜è¾ƒå°‘({gpu_memory}GB)ï¼Œå¼ºçƒˆæ¨è4bité‡åŒ–ï¼Œbatch_size=1"
                }

        return jsonify({
            "status": "success",
            "cuda_available": cuda_available,
            "gpu_info": gpu_info,
            "recommendations": recommendations,
            "quantization_options": {
                "4bit": {
                    "description": "4bité‡åŒ–ï¼Œæœ€èŠ‚çœå†…å­˜",
                    "memory_reduction": "çº¦75%",
                    "speed": "è¾ƒå¿«",
                    "quality": "è½»å¾®æŸå¤±"
                },
                "8bit": {
                    "description": "8bité‡åŒ–ï¼Œå¹³è¡¡æ€§èƒ½å’Œå†…å­˜",
                    "memory_reduction": "çº¦50%",
                    "speed": "ä¸­ç­‰",
                    "quality": "å‡ ä¹æ— æŸå¤±"
                },
                "full": {
                    "description": "å…¨ç²¾åº¦è®­ç»ƒï¼Œæœ€é«˜è´¨é‡",
                    "memory_reduction": "0%",
                    "speed": "æœ€å¿«",
                    "quality": "æ— æŸå¤±"
                }
            }
        })

    except Exception as e:
        logger.error(f"è·å–é‡åŒ–ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })

@app.route('/api/discover_models', methods=['GET'])
def discover_models():
    """å‘ç°å¯ç”¨çš„æ¨¡å‹"""
    try:
        models_dir = 'models'
        available_models = []

        # æ£€æŸ¥modelsç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(models_dir):
            os.makedirs(models_dir, exist_ok=True)
            logger.info("åˆ›å»ºäº†modelsç›®å½•")

        # éå†modelsç›®å½•
        for item in os.listdir(models_dir):
            item_path = os.path.join(models_dir, item)

            # åªå¤„ç†æ–‡ä»¶å¤¹
            if os.path.isdir(item_path):
                model_info = {
                    "name": item,
                    "path": item_path,
                    "display_name": item,
                    "valid": False,
                    "size": 0,
                    "files": []
                }

                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æ¨¡å‹ç›®å½•
                model_files = []
                total_size = 0

                try:
                    for root, dirs, files in os.walk(item_path):
                        for file in files:
                            file_path = os.path.join(root, file)
                            file_size = os.path.getsize(file_path)
                            total_size += file_size

                            # æ£€æŸ¥å…³é”®æ¨¡å‹æ–‡ä»¶
                            if file.endswith(('.bin', '.safetensors', '.pt', '.pth', '.ckpt')):
                                model_files.append({
                                    "name": file,
                                    "size": file_size,
                                    "type": "model"
                                })
                            elif file in ['config.json', 'tokenizer.json', 'tokenizer_config.json']:
                                model_files.append({
                                    "name": file,
                                    "size": file_size,
                                    "type": "config"
                                })
                            elif file in ['vocab.txt', 'merges.txt', 'special_tokens_map.json']:
                                model_files.append({
                                    "name": file,
                                    "size": file_size,
                                    "type": "tokenizer"
                                })

                except Exception as e:
                    logger.warning(f"æ‰«ææ¨¡å‹ç›®å½• {item_path} æ—¶å‡ºé”™: {e}")
                    continue

                # åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆæ¨¡å‹
                has_model_file = any(f['type'] == 'model' for f in model_files)
                has_config = any(f['type'] == 'config' for f in model_files)

                if has_model_file or has_config:
                    model_info["valid"] = True

                model_info["size"] = total_size
                model_info["files"] = model_files

                # ç”Ÿæˆæ›´å‹å¥½çš„æ˜¾ç¤ºåç§°
                if "deepseek" in item.lower():
                    model_info["display_name"] = f"ğŸ§  DeepSeek - {item}"
                elif "chatglm" in item.lower():
                    model_info["display_name"] = f"ğŸ’¬ ChatGLM - {item}"
                elif "qwen" in item.lower():
                    model_info["display_name"] = f"ğŸ”® Qwen - {item}"
                elif "llama" in item.lower():
                    model_info["display_name"] = f"ğŸ¦™ LLaMA - {item}"
                else:
                    model_info["display_name"] = f"ğŸ¤– {item}"

                available_models.append(model_info)

        # æŒ‰æœ‰æ•ˆæ€§å’Œåç§°æ’åº
        available_models.sort(key=lambda x: (not x["valid"], x["name"]))

        logger.info(f"å‘ç° {len(available_models)} ä¸ªæ¨¡å‹ç›®å½•")

        return jsonify({
            "status": "success",
            "models": available_models,
            "count": len(available_models)
        })

    except Exception as e:
        logger.error(f"æ¨¡å‹å‘ç°å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })

@app.route('/api/get_model_info', methods=['POST'])
def get_model_info():
    """è·å–ç‰¹å®šæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯"""
    try:
        data = request.json
        model_path = data.get('model_path', '')

        if not model_path or not os.path.exists(model_path):
            return jsonify({
                "status": "error",
                "message": "æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨"
            })

        model_info = {
            "path": model_path,
            "name": os.path.basename(model_path),
            "files": [],
            "total_size": 0,
            "model_files_count": 0,
            "config_files": [],
            "tokenizer_files": []
        }

        # æ‰«ææ¨¡å‹æ–‡ä»¶
        for root, dirs, files in os.walk(model_path):
            for file in files:
                file_path = os.path.join(root, file)
                try:
                    file_size = os.path.getsize(file_path)
                    model_info["total_size"] += file_size

                    relative_path = os.path.relpath(file_path, model_path)

                    file_info = {
                        "name": file,
                        "path": relative_path,
                        "size": file_size,
                        "size_mb": round(file_size / (1024 * 1024), 2)
                    }

                    if file.endswith(('.bin', '.safetensors', '.pt', '.pth', '.ckpt')):
                        file_info["type"] = "model"
                        model_info["model_files_count"] += 1
                    elif file == 'config.json':
                        file_info["type"] = "config"
                        model_info["config_files"].append(file_info)

                        # å°è¯•è¯»å–é…ç½®ä¿¡æ¯
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                config = json.load(f)
                                model_info["model_type"] = config.get("model_type", "unknown")
                                model_info["architectures"] = config.get("architectures", [])
                                model_info["vocab_size"] = config.get("vocab_size", 0)
                        except:
                            pass
                    elif file in ['tokenizer.json', 'tokenizer_config.json', 'vocab.txt', 'merges.txt']:
                        file_info["type"] = "tokenizer"
                        model_info["tokenizer_files"].append(file_info)
                    else:
                        file_info["type"] = "other"

                    model_info["files"].append(file_info)

                except Exception as e:
                    logger.warning(f"æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯ {file_path}: {e}")
                    continue

        # è½¬æ¢æ€»å¤§å°ä¸ºå¯è¯»æ ¼å¼
        total_size_mb = model_info["total_size"] / (1024 * 1024)
        if total_size_mb > 1024:
            model_info["total_size_display"] = f"{total_size_mb / 1024:.1f} GB"
        else:
            model_info["total_size_display"] = f"{total_size_mb:.1f} MB"

        return jsonify({
            "status": "success",
            "model_info": model_info
        })

    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })

def format_file_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    elif size_bytes < 1024 * 1024 * 1024:
        return f"{size_bytes / (1024 * 1024):.1f} MB"
    else:
        return f"{size_bytes / (1024 * 1024 * 1024):.1f} GB"
# ======================== çŸ¥è¯†å›¾è°±API ========================

@app.route('/api/connect_neo4j', methods=['POST'])
def connect_neo4j():
    """è¿æ¥Neo4jæ•°æ®åº“"""
    try:
        data = request.json
        uri = data.get('uri', 'bolt://localhost:7687')
        user = data.get('user', 'neo4j')
        password = data.get('password', 'password')

        services['knowledge_graph'] = KnowledgeGraph(uri, user, password)
        services['knowledge_processor'] = EducationKnowledgeProcessor(uri, user, password)

        # æµ‹è¯•è¿æ¥
        test_result = services['knowledge_graph'].query("RETURN 1 as test")
        if test_result:
            system_status['neo4j_connected'] = True
            logger.info("Neo4jè¿æ¥æˆåŠŸ")
            return jsonify({
                "status": "success",
                "message": "æ•°æ®åº“è¿æ¥æˆåŠŸ"
            })
        else:
            raise Exception("è¿æ¥æµ‹è¯•å¤±è´¥")

    except Exception as e:
        logger.error(f"Neo4jè¿æ¥å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/disconnect_neo4j', methods=['POST'])
def disconnect_neo4j():
    """æ–­å¼€Neo4jè¿æ¥"""
    try:
        if services['knowledge_graph']:
            services['knowledge_graph'].close()

        services['knowledge_graph'] = None
        services['knowledge_processor'] = None
        system_status['neo4j_connected'] = False

        logger.info("Neo4jè¿æ¥å·²æ–­å¼€")
        return jsonify({
            "status": "success",
            "message": "æ•°æ®åº“è¿æ¥å·²æ–­å¼€"
        })

    except Exception as e:
        logger.error(f"æ–­å¼€è¿æ¥å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/import_knowledge', methods=['POST'])
def import_knowledge():
    """å¯¼å…¥çŸ¥è¯†"""
    try:
        if not services['knowledge_processor']:
            return jsonify({
                "status": "error",
                "message": "æœªè¿æ¥çŸ¥è¯†å›¾è°±æ•°æ®åº“"
            })

        if 'knowledge_file' not in request.files:
            return jsonify({
                "status": "error",
                "message": "æœªæ‰¾åˆ°çŸ¥è¯†æ–‡ä»¶"
            })

        file = request.files['knowledge_file']
        if file.filename == '':
            return jsonify({
                "status": "error",
                "message": "æœªé€‰æ‹©æ–‡ä»¶"
            })

        # ä¿å­˜æ–‡ä»¶
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)

        # å¯¼å…¥çŸ¥è¯†
        knowledge_items = services['knowledge_processor'].extract_from_file(filepath)
        count = services['knowledge_processor'].build_knowledge_graph(knowledge_items)

        logger.info(f"çŸ¥è¯†å¯¼å…¥æˆåŠŸï¼Œå…±å¯¼å…¥{count}æ¡")
        return jsonify({
            "status": "success",
            "message": "çŸ¥è¯†å¯¼å…¥æˆåŠŸ",
            "count": count
        })

    except Exception as e:
        logger.error(f"çŸ¥è¯†å¯¼å…¥å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/generate_sample_knowledge', methods=['POST'])
def generate_sample_knowledge():
    """ç”Ÿæˆç¤ºä¾‹çŸ¥è¯†"""
    try:
        if not services['knowledge_processor']:
            return jsonify({
                "status": "error",
                "message": "æœªè¿æ¥çŸ¥è¯†å›¾è°±æ•°æ®åº“"
            })

        count = services['knowledge_processor'].create_educational_knowledge_base()

        logger.info("ç¤ºä¾‹çŸ¥è¯†ç”ŸæˆæˆåŠŸ")
        return jsonify({
            "status": "success",
            "message": "ç¤ºä¾‹çŸ¥è¯†ç”ŸæˆæˆåŠŸ",
            "count": count
        })

    except Exception as e:
        logger.error(f"ç¤ºä¾‹çŸ¥è¯†ç”Ÿæˆå¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/execute_cypher', methods=['POST'])
def execute_cypher():
    """æ‰§è¡ŒCypheræŸ¥è¯¢"""
    try:
        if not services['knowledge_graph']:
            return jsonify({
                "status": "error",
                "message": "æœªè¿æ¥Neo4jæ•°æ®åº“"
            })

        data = request.json
        query = data.get('query', '')

        if not query.strip():
            return jsonify({
                "status": "error",
                "message": "æŸ¥è¯¢è¯­å¥ä¸èƒ½ä¸ºç©º"
            })

        results = services['knowledge_graph'].query(query)

        # å°†ç»“æœè½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–çš„æ ¼å¼
        serializable_results = []
        for record in results:
            serializable_record = {}
            for key, value in record.items():
                if hasattr(value, '_properties'):
                    # Neo4jèŠ‚ç‚¹æˆ–å…³ç³»
                    serializable_record[key] = dict(value)
                else:
                    serializable_record[key] = value
            serializable_results.append(serializable_record)

        return jsonify({
            "status": "success",
            "data": serializable_results
        })

    except Exception as e:
        logger.error(f"CypheræŸ¥è¯¢å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })

@app.route('/api/get_graph_stats', methods=['GET'])
def get_graph_stats():
    """è·å–å›¾è°±ç»Ÿè®¡ä¿¡æ¯"""
    try:
        if not services['knowledge_graph']:
            return jsonify({
                "status": "error",
                "message": "æœªè¿æ¥Neo4jæ•°æ®åº“"
            })

        # è·å–èŠ‚ç‚¹æ•°é‡
        node_result = services['knowledge_graph'].query("MATCH (n) RETURN count(n) as count")
        node_count = node_result[0]['count'] if node_result else 0

        # è·å–å…³ç³»æ•°é‡
        rel_result = services['knowledge_graph'].query("MATCH ()-[r]->() RETURN count(r) as count")
        rel_count = rel_result[0]['count'] if rel_result else 0

        # è·å–åŸŸæ•°é‡ï¼ˆå‡è®¾é€šè¿‡domainå±æ€§åŒºåˆ†ï¼‰
        domain_result = services['knowledge_graph'].query(
            "MATCH (n) WHERE n.domain IS NOT NULL RETURN count(DISTINCT n.domain) as count"
        )
        domain_count = domain_result[0]['count'] if domain_result else 0

        return jsonify({
            "status": "success",
            "stats": {
                "nodes": node_count,
                "relationships": rel_count,
                "domains": domain_count
            }
        })

    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


# ======================== å¤šæ¨¡æ€äº¤äº’API ========================

@app.route('/api/recognize_speech', methods=['POST'])
def recognize_speech():
    """è¯­éŸ³è¯†åˆ«"""
    try:
        if not services['speech_recognizer']:
            return jsonify({
                "status": "error",
                "message": "è¯­éŸ³è¯†åˆ«æœåŠ¡æœªåˆå§‹åŒ–"
            })

        if 'audio_file' not in request.files:
            return jsonify({
                "status": "error",
                "message": "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶"
            })

        file = request.files['audio_file']
        if file.filename == '':
            return jsonify({
                "status": "error",
                "message": "æœªé€‰æ‹©æ–‡ä»¶"
            })

        # ä¿å­˜æ–‡ä»¶
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)

        # è¯†åˆ«è¯­éŸ³
        text = services['speech_recognizer'].recognize_from_file(filepath)

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.remove(filepath)

        return jsonify({
            "status": "success",
            "text": text
        })

    except Exception as e:
        logger.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/recognize_image', methods=['POST'])
def recognize_image():
    """å›¾åƒè¯†åˆ«"""
    try:
        if not services['image_recognizer']:
            return jsonify({
                "status": "error",
                "message": "å›¾åƒè¯†åˆ«æœåŠ¡æœªåˆå§‹åŒ–"
            })

        if 'image_file' not in request.files:
            return jsonify({
                "status": "error",
                "message": "æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶"
            })

        file = request.files['image_file']
        if file.filename == '':
            return jsonify({
                "status": "error",
                "message": "æœªé€‰æ‹©æ–‡ä»¶"
            })

        # ä¿å­˜æ–‡ä»¶
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)

        # è¯†åˆ«å›¾åƒ
        result = services['image_recognizer'].recognize_image(filepath)

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.remove(filepath)

        # æ·»åŠ ç½®ä¿¡åº¦ï¼ˆç¤ºä¾‹ï¼‰
        result['confidence'] = 0.85

        return jsonify({
            "status": "success",
            "result": result
        })

    except Exception as e:
        logger.error(f"å›¾åƒè¯†åˆ«å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/process_text', methods=['POST'])
def process_text():
    """æ–‡æœ¬å¤„ç†"""
    try:
        if not services['text_processor']:
            return jsonify({
                "status": "error",
                "message": "æ–‡æœ¬å¤„ç†æœåŠ¡æœªåˆå§‹åŒ–"
            })

        data = request.json
        text = data.get('text', '')

        if not text.strip():
            return jsonify({
                "status": "error",
                "message": "æ–‡æœ¬ä¸èƒ½ä¸ºç©º"
            })

        # å¤„ç†æ–‡æœ¬
        tokens = services['text_processor'].preprocess_text(text)
        keywords = services['text_processor'].extract_keywords(text)
        question_type = services['text_processor'].classify_question(text)

        return jsonify({
            "status": "success",
            "tokens": tokens,
            "keywords": keywords,
            "question_type": question_type
        })

    except Exception as e:
        logger.error(f"æ–‡æœ¬å¤„ç†å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/extract_keywords', methods=['POST'])
def extract_keywords():
    """æå–å…³é”®è¯"""
    try:
        if not services['text_processor']:
            return jsonify({
                "status": "error",
                "message": "æ–‡æœ¬å¤„ç†æœåŠ¡æœªåˆå§‹åŒ–"
            })

        data = request.json
        text = data.get('text', '')

        if not text.strip():
            return jsonify({
                "status": "error",
                "message": "æ–‡æœ¬ä¸èƒ½ä¸ºç©º"
            })

        keywords = services['text_processor'].extract_keywords(text, top_k=10)

        return jsonify({
            "status": "success",
            "keywords": keywords
        })

    except Exception as e:
        logger.error(f"å…³é”®è¯æå–å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


# ======================== æ™ºèƒ½æ•™å­¦API ========================

@app.route('/api/add_student', methods=['POST'])
def add_student():
    """æ·»åŠ å­¦ç”Ÿ"""
    try:
        # åˆå§‹åŒ–æ•™å­¦æœåŠ¡ï¼ˆå¦‚æœå°šæœªåˆå§‹åŒ–ï¼‰
        if not services['teaching']:
            services['teaching'] = PersonalizedTeaching()

        data = request.json
        name = data.get('name', '')
        learning_style = data.get('learning_style', 'visual')

        if not name.strip():
            return jsonify({
                "status": "error",
                "message": "å­¦ç”Ÿå§“åä¸èƒ½ä¸ºç©º"
            })

        # ç”Ÿæˆå­¦ç”ŸID
        student_id = str(uuid.uuid4())[:8]

        # æ·»åŠ å­¦ç”Ÿæ¡£æ¡ˆ
        success = services['teaching'].add_student_profile(student_id, name)

        if success:
            # è®¾ç½®å­¦ä¹ é£æ ¼
            profile = services['teaching'].get_student_profile(student_id)
            profile.set_learning_style(learning_style)

            logger.info(f"æ·»åŠ å­¦ç”ŸæˆåŠŸ: {name} ({student_id})")
            return jsonify({
                "status": "success",
                "student_id": student_id,
                "message": "å­¦ç”Ÿæ·»åŠ æˆåŠŸ"
            })
        else:
            return jsonify({
                "status": "error",
                "message": "å­¦ç”Ÿæ·»åŠ å¤±è´¥"
            })

    except Exception as e:
        logger.error(f"æ·»åŠ å­¦ç”Ÿå¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/get_students', methods=['GET'])
def get_students():
    """è·å–å­¦ç”Ÿåˆ—è¡¨"""
    try:
        if not services['teaching']:
            services['teaching'] = PersonalizedTeaching()
            # åˆ›å»ºç¤ºä¾‹å­¦ç”Ÿæ¡£æ¡ˆ
            services['teaching'].create_demo_student_profiles()

        students = []
        for student_id, profile in services['teaching'].student_profiles.items():
            students.append({
                "id": student_id,
                "name": profile.name,
                "learning_style": profile.learning_style
            })

        return jsonify({
            "status": "success",
            "students": students
        })

    except Exception as e:
        logger.error(f"è·å–å­¦ç”Ÿåˆ—è¡¨å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/get_student_profile', methods=['POST'])
def get_student_profile():
    """è·å–å­¦ç”Ÿæ¡£æ¡ˆ"""
    try:
        if not services['teaching']:
            return jsonify({
                "status": "error",
                "message": "æ•™å­¦æœåŠ¡æœªåˆå§‹åŒ–"
            })

        data = request.json
        student_id = data.get('student_id', '')

        profile = services['teaching'].get_student_profile(student_id)

        if profile:
            return jsonify({
                "status": "success",
                "profile": {
                    "student_id": profile.student_id,
                    "name": profile.name,
                    "learning_style": profile.learning_style,
                    "strengths": profile.get_top_strengths(5),
                    "weaknesses": profile.get_top_weaknesses(5),
                    "preferences": profile.get_top_preferences(5)
                }
            })
        else:
            return jsonify({
                "status": "error",
                "message": "å­¦ç”Ÿæ¡£æ¡ˆä¸å­˜åœ¨"
            })

    except Exception as e:
        logger.error(f"è·å–å­¦ç”Ÿæ¡£æ¡ˆå¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/generate_learning_path', methods=['POST'])
def generate_learning_path():
    """ç”Ÿæˆå­¦ä¹ è·¯å¾„"""
    try:
        if not services['teaching']:
            return jsonify({
                "status": "error",
                "message": "æ•™å­¦æœåŠ¡æœªåˆå§‹åŒ–"
            })

        data = request.json
        student_id = data.get('student_id', '')
        goal = data.get('goal', '')

        if not student_id or not goal:
            return jsonify({
                "status": "error",
                "message": "å­¦ç”ŸIDå’Œå­¦ä¹ ç›®æ ‡ä¸èƒ½ä¸ºç©º"
            })

        learning_path = services['teaching'].generate_learning_path(student_id, goal)

        if learning_path:
            return jsonify({
                "status": "success",
                "learning_path": learning_path['learning_path']
            })
        else:
            return jsonify({
                "status": "error",
                "message": "å­¦ä¹ è·¯å¾„ç”Ÿæˆå¤±è´¥"
            })

    except Exception as e:
        logger.error(f"å­¦ä¹ è·¯å¾„ç”Ÿæˆå¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/chat', methods=['POST'])
def chat():
    """æ™ºèƒ½å¯¹è¯"""
    try:
        if not services['teaching']:
            return jsonify({
                "status": "error",
                "message": "æ•™å­¦æœåŠ¡æœªåˆå§‹åŒ–"
            })

        data = request.json
        message = data.get('message', '')
        student_id = data.get('student_id', '')

        if not message.strip():
            return jsonify({
                "status": "error",
                "message": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"
            })

        if student_id:
            # ä¸ªæ€§åŒ–å›ç­”
            response = services['teaching'].generate_personalized_answer(student_id, message)

            # è®°å½•å­¦ä¹ äº¤äº’
            services['teaching'].add_learning_interaction(student_id, "general", message)
        else:
            # é€šç”¨å›ç­”
            if services['llm']:
                response = services['llm'].generate_response(message)
            else:
                response = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚è¯·ç¡®ä¿å·²åŠ è½½è¯­è¨€æ¨¡å‹ã€‚"

        return jsonify({
            "status": "success",
            "response": response
        })

    except Exception as e:
        logger.error(f"æ™ºèƒ½å¯¹è¯å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/get_recommendations', methods=['POST'])
def get_recommendations():
    """è·å–èµ„æºæ¨è"""
    try:
        if not services['teaching']:
            return jsonify({
                "status": "error",
                "message": "æ•™å­¦æœåŠ¡æœªåˆå§‹åŒ–"
            })

        data = request.json
        topic = data.get('topic', '')
        student_id = data.get('student_id', '')

        if not topic:
            return jsonify({
                "status": "error",
                "message": "ä¸»é¢˜ä¸èƒ½ä¸ºç©º"
            })

        if student_id:
            resources = services['teaching'].recommend_learning_resources(student_id, topic, count=5)
        else:
            # è¿”å›é€šç”¨æ¨è
            resources = [
                {
                    "title": f"{topic}å…¥é—¨æ•™ç¨‹",
                    "type": "video",
                    "description": f"é€‚åˆåˆå­¦è€…çš„{topic}è§†é¢‘æ•™ç¨‹"
                },
                {
                    "title": f"{topic}å®è·µæŒ‡å—",
                    "type": "article",
                    "description": f"{topic}çš„å®é™…åº”ç”¨æ¡ˆä¾‹å’Œç»ƒä¹ "
                },
                {
                    "title": f"{topic}è¿›é˜¶è¯¾ç¨‹",
                    "type": "course",
                    "description": f"æ·±å…¥å­¦ä¹ {topic}çš„é«˜çº§è¯¾ç¨‹"
                }
            ]

        return jsonify({
            "status": "success",
            "resources": resources
        })

    except Exception as e:
        logger.error(f"è·å–æ¨èå¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/generate_report', methods=['POST'])
def generate_report():
    """ç”Ÿæˆå­¦ä¹ æŠ¥å‘Š"""
    try:
        if not services['teaching']:
            return jsonify({
                "status": "error",
                "message": "æ•™å­¦æœåŠ¡æœªåˆå§‹åŒ–"
            })

        data = request.json
        student_id = data.get('student_id', '')
        report_type = data.get('report_type', 'progress')
        time_range = data.get('time_range', 'week')

        if not student_id:
            return jsonify({
                "status": "error",
                "message": "å­¦ç”ŸIDä¸èƒ½ä¸ºç©º"
            })

        profile = services['teaching'].get_student_profile(student_id)
        if not profile:
            return jsonify({
                "status": "error",
                "message": "å­¦ç”Ÿæ¡£æ¡ˆä¸å­˜åœ¨"
            })

        # ç”ŸæˆæŠ¥å‘ŠHTML
        report_html = f"""
        <div class="report">
            <h3>{profile.name}çš„å­¦ä¹ æŠ¥å‘Š</h3>
            <p><strong>æŠ¥å‘Šç±»å‹:</strong> {report_type}</p>
            <p><strong>æ—¶é—´èŒƒå›´:</strong> {time_range}</p>
            <p><strong>ç”Ÿæˆæ—¶é—´:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>

            <h4>å­¦ä¹ ä¼˜åŠ¿</h4>
            <ul>
        """

        strengths = profile.get_top_strengths(3)
        for topic, score in strengths:
            report_html += f"<li>{topic}: {score:.1f}åˆ†</li>"

        report_html += """
            </ul>

            <h4>éœ€è¦æ”¹è¿›çš„é¢†åŸŸ</h4>
            <ul>
        """

        weaknesses = profile.get_top_weaknesses(3)
        for topic, score in weaknesses:
            report_html += f"<li>{topic}: éœ€è¦åŠ å¼º</li>"

        report_html += """
            </ul>

            <h4>å­¦ä¹ å»ºè®®</h4>
            <p>å»ºè®®ç»§ç»­ä¿æŒåœ¨ä¼˜åŠ¿é¢†åŸŸçš„å­¦ä¹ ï¼ŒåŒæ—¶åŠ å¼ºè–„å¼±ç¯èŠ‚çš„ç»ƒä¹ ã€‚</p>
        </div>
        """

        return jsonify({
            "status": "success",
            "report_html": report_html
        })

    except Exception as e:
        logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/api/export_report', methods=['POST'])
def export_report():
    """å¯¼å‡ºæŠ¥å‘Š"""
    try:
        data = request.json
        content = data.get('content', '')
        format_type = data.get('format', 'html')

        if not content:
            return jsonify({
                "status": "error",
                "message": "æŠ¥å‘Šå†…å®¹ä¸èƒ½ä¸ºç©º"
            })

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"learning_report_{timestamp}.html"
        filepath = os.path.join(REPORTS_FOLDER, filename)

        # åˆ›å»ºå®Œæ•´çš„HTMLæ–‡ä»¶
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>å­¦ä¹ æŠ¥å‘Š</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; }}
                .report {{ max-width: 800px; margin: 0 auto; }}
                h3 {{ color: #333; }}
                h4 {{ color: #666; }}
                ul {{ margin: 10px 0; }}
                li {{ margin: 5px 0; }}
            </style>
        </head>
        <body>
            {content}
        </body>
        </html>
        """

        # ä¿å­˜æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(html_content)

        return jsonify({
            "status": "success",
            "download_url": f"/download_report/{filename}",
            "filename": filename
        })

    except Exception as e:
        logger.error(f"æŠ¥å‘Šå¯¼å‡ºå¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        })


@app.route('/download_report/<filename>')
def download_report(filename):
    """ä¸‹è½½æŠ¥å‘Šæ–‡ä»¶"""
    try:
        filepath = os.path.join(REPORTS_FOLDER, filename)
        if os.path.exists(filepath):
            return send_file(filepath, as_attachment=True, download_name=filename)
        else:
            return jsonify({
                "status": "error",
                "message": "æ–‡ä»¶ä¸å­˜åœ¨"
            }), 404
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸‹è½½å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500


# ======================== ç³»ç»ŸAPI ========================

@app.route('/api/system_status', methods=['GET'])
def get_system_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    return jsonify({
        "status": "success",
        "system_status": system_status,
        "services": {
            "llm": services['llm'] is not None,
            "knowledge_graph": services['knowledge_graph'] is not None,
            "teaching": services['teaching'] is not None,
            "speech_recognizer": services['speech_recognizer'] is not None,
            "image_recognizer": services['image_recognizer'] is not None,
            "text_processor": services['text_processor'] is not None
        }
    })


@app.route('/')
def index():
    """ä¸»é¡µ"""
    try:
        # å°è¯•åŠ è½½HTMLæ¨¡æ¿
        template_path = os.path.join('interface', 'web_console', 'templates', 'index.html')
        if os.path.exists(template_path):
            with open(template_path, 'r', encoding='utf-8') as f:
                html_content = f.read()
            return html_content
        else:
            return
    except Exception as e:
        logger.error(f"ä¸»é¡µè·¯ç”±å‡ºé”™: {e}")
        return f"<h1>ç³»ç»Ÿé”™è¯¯</h1><p>{str(e)}</p>"


# é”™è¯¯å¤„ç†
@app.errorhandler(404)
def not_found(error):
    return jsonify({
        "status": "error",
        "message": "APIæ¥å£ä¸å­˜åœ¨"
    }), 404


@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        "status": "error",
        "message": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"
    }), 500


if __name__ == '__main__':
    # åˆå§‹åŒ–æœåŠ¡
    initialize_services()

    logger.info("PEPPERæ™ºèƒ½æ•™å­¦ç³»ç»ŸAPIæœåŠ¡å™¨å¯åŠ¨ä¸­...")
    logger.info("è®¿é—®åœ°å€: http://localhost:5000")

    # å¯åŠ¨Flaskåº”ç”¨
    app.run(host='0.0.0.0', port=5000, debug=True)